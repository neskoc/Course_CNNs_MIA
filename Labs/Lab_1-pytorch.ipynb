{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment 1 - Malaria Cell Image Classification\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "Office hours: Mondays 13.15--15.00 (Tommy), Tuesdays 13.15--16.00 (Minh), Thursdays 08.15--12.00 (Attila)\n",
    "\n",
    "Welcome. The first assignment is based on classifying images of cells, whether they are parasitized or uninfected by malaria. Your input will be an image of a cell, and your output is a binary classifier. It is based on an open dataset, available from Lister Hill National Center for Biomedical Communications (NIH): https://lhncbc.nlm.nih.gov/publication/pub9932. You need to download the file ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip (as described in the assignment instructions). The data was preprocessed and organized for easier machine learning applications.\n",
    "\n",
    "Your task is to look through the highly customizable code below, which contains all the main steps for high accuracy classification of these data, and improve upon the model. The most important issues with the current code are noted in the comments for easier comprehension. Your tasks, to include in the report, are:\n",
    "\n",
    "- Reach an accuracy of at least 96~\\% on the validation dataset.\n",
    "- Plot the training/validating losses and accuracies. Describe when to stop training, and why that is a good choice.\n",
    "- Describe the thought process behind building your model and choosing the model hyper-parameters.\n",
    "- Describe what you think are the biggest issues with the current setup, and how to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages for loading the dataset\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt  # Package for plotting\n",
    "import os\n",
    "import numpy as np  # Package for matrix operations, handling data\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "# See if GPU is available to use\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False\n",
    "    \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset downloaded from the provided link\n",
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, \"data/cell_images\")  # Path to dataset\n",
    "\n",
    "# Check out dataset\n",
    "parasitized_data = os.listdir(data_path + '/Parasitized/')\n",
    "print(parasitized_data[:2])  # the output we get are the .png files\n",
    "print(\"Number of parasitized images: \" + str(len(parasitized_data)) + '\\n')\n",
    "uninfected_data = os.listdir(data_path + '/Uninfected/')\n",
    "print(uninfected_data[:2])\n",
    "print(\"Number of non-paratisized images: \" + str(len(uninfected_data)))\n",
    "\n",
    "# NOTE: The images are in .png format, they will have to be loaded individually and handled accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some sample images\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    img = plt.imread(data_path + '/Parasitized/' + parasitized_data[i])\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image size: ' + str(np.shape(img)))\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Parasitized Image Samples')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    img = plt.imread(data_path + '/Uninfected/' + uninfected_data[i + 1])\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image size: ' + str(np.shape(img)))\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Uninfected Image Samples')\n",
    "plt.show()\n",
    "\n",
    "# NOTE: The images are of different size. Also they are RGB images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset preprocessing so far has been to help you, you should not change anything. However, from now on, take nothing for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training/validation/testing data\n",
    "transformation = transforms.Compose([transforms.Resize((16, 16)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Split dataset into training and testing dataset\n",
    "dataset = datasets.ImageFolder(root=data_path, transform=transformation)\n",
    "\n",
    "# Find number of train/val/test images\n",
    "num_images = len(dataset.targets)\n",
    "test_size = 0.2\n",
    "num_train = int((1-test_size)*num_images)\n",
    "num_test = num_images - num_train\n",
    "num_val = int(num_test/2)\n",
    "num_test = num_test - num_val\n",
    "print(\"Number of train: {} \\t val: {} \\t test: {}\".format(\n",
    "    num_train, num_val, num_test))\n",
    "# NOTE: Keep the ratio of the split as it is. It will make evaluation easier for us.\n",
    "# NOTE: The split should be reproducible, hence the random state.\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, [num_train, num_val, num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loader\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# Val loader\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "# Test loader\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CellModel, self).__init__()\n",
    "        # input is 16x16\n",
    "        # padding=1 for same padding\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        # feature map size is 8x8 by pooling\n",
    "        # padding=1 for same padding\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        # feature map size is 4x4 by pooling\n",
    "        self.fc1 = nn.Linear(8*4*4, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Is the 'hotmap' activation layer in the model?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are the model parameters split \"evenly\" between the layers? Or is there one huge layer?\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?   \n",
    "\n",
    "\n",
    "# NOTE: Are you satisfied with the loss function?\n",
    "# NOTE: Are you satisfied with the metric?\n",
    "# NOTE: Are you satisfied with the optimizer and its parameters?\n",
    "\n",
    "    \n",
    "model = CellModel()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# check model parameter\n",
    "for p in model.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accu = []\n",
    "i = 0\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()    # calc gradients\n",
    "        train_loss.append(loss.item())\n",
    "        optimizer.step()   # update gradients\n",
    "        prediction = output.data.max(1)[1]   # first column has actual prob.\n",
    "        accuracy = prediction.eq(target.data).sum().item()/batch_size*100\n",
    "        train_accu.append(accuracy)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {}\\t Step: {} \\t\\t Loss: {:.3f} \\t Accuracy: {:.3f}'.format(\n",
    "                epoch, i, loss.item(), accuracy))\n",
    "        i += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            prediction = output.data.max(1)[1]\n",
    "            correct += prediction.eq(target.data).sum()\n",
    "\n",
    "        print('Validation accuracy: {:.2f}%'.format(\n",
    "            100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        prediction = output.data.max(1)[1]\n",
    "        correct += prediction.eq(target.data).sum()\n",
    "\n",
    "    print('Testing accuracy: {:.2f}%'.format(\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
