{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_deep_cnn_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGPd6uKysaAC"
      },
      "source": [
        "# Multi-class classification of handwritten digits using a deep CNN model\n",
        "\n",
        "Using the canonical MNIST dataset of hand-written digits.\n",
        "\n",
        "More information about this dataset here:\n",
        " * https://keras.io/api/datasets/mnist/\n",
        " * http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV4yMnunsaS3"
      },
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Make the results reproducible\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "import sklearn.svm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.datasets\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.set_image_data_format(\"channels_last\")\n",
        "\n",
        "print(f\"Tensorflow version: {tensorflow.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xhXORz6SgA"
      },
      "source": [
        "# Load and set up the data\n",
        "(X, y), (X_val, y_val) = tensorflow.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Use the last 2000 samples of the given validation set as test set\n",
        "X_test = X_val[-2000:, :]\n",
        "y_test = y_val[-2000:]\n",
        "X_val = X_val[:-2000, :]\n",
        "y_val = y_val[:-2000]\n",
        "\n",
        "# Add channel dimensions last\n",
        "X = X[..., np.newaxis]\n",
        "X_val = X_val[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "# Convert to 32-bit floating-point numbers (default in keras/tensorflow)\n",
        "X = X.astype(np.float32)\n",
        "X_val = X_val.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# Scale to [0, 1]\n",
        "X /= 255.0\n",
        "X_val /= 255.0\n",
        "X_test /= 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxp5xH5U6OvM"
      },
      "source": [
        "# Plot some example images\n",
        "fig = plt.figure(figsize=(14.0, 3.25))\n",
        "fig.subplots_adjust(top=0.85,\n",
        "                    bottom=0.01,\n",
        "                    left=0.01,\n",
        "                    right=0.99,\n",
        "                    wspace=0.0,\n",
        "                    hspace=0.0)\n",
        "ax_i = 1\n",
        "for i in range(2):\n",
        "    for j in range(10):\n",
        "        plt.subplot(2, 10, ax_i)\n",
        "        ax = plt.gca()\n",
        "        plt.setp(ax.get_xticklabels(), visible=False)\n",
        "        plt.setp(ax.get_yticklabels(), visible=False)\n",
        "        im = X[np.random.randint(X.shape[0]), :, :, 0]\n",
        "        ax.imshow(im, cmap=plt.get_cmap(\"Greys\"))\n",
        "        ax_i += 1\n",
        "plt.suptitle(\"Example images from the MNIST dataset\", fontsize=26)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJjY4_gl5DyM"
      },
      "source": [
        "# Convert the outputs to one-hot encoded (output classes instead of 0-9 output)\n",
        "num_classes = len(set(y))\n",
        "\n",
        "y_orig = y.copy()\n",
        "y_val_orig = y_val.copy()\n",
        "y = tensorflow.keras.utils.to_categorical(y, num_classes)\n",
        "y_val = tensorflow.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "input_shape = (*X.shape[1:3], 1)\n",
        "\n",
        "print(f\"Training set size X  : {X.shape}\")\n",
        "print(f\"Training set size y  : {y.shape}\")\n",
        "print(f\"Validation set size X: {X_val.shape}\")\n",
        "print(f\"Validation set size y: {y_val.shape}\")\n",
        "print(f\"Test set size X      : {X_test.shape}\")\n",
        "print(f\"Test set size y      : {y_test.shape}\")\n",
        "print(f\"Input shape          : {input_shape}\")\n",
        "print(f\"Number of classes    : {num_classes}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w06KHXXsyXO"
      },
      "source": [
        "# Create baseline model\n",
        "\n",
        "# Reshape for the support vector machine (SVC) model\n",
        "X_ = X.reshape(X.shape[0], -1)\n",
        "X_val_ = X_val.reshape(X_val.shape[0], -1)\n",
        "X_test_ = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Fit baseline model\n",
        "model_baseline = sklearn.svm.SVC(C=1.0,\n",
        "                                 kernel=\"rbf\",\n",
        "                                 gamma=\"auto\",\n",
        "                                 shrinking=True,\n",
        "                                 tol=0.001,\n",
        "                                 cache_size=200,\n",
        "                                 class_weight=None,\n",
        "                                 verbose=True,\n",
        "                                 max_iter=5,  # Note, only five iterations here!\n",
        "                                 decision_function_shape=\"ovr\")\n",
        "_ = model_baseline.fit(X_, y_orig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuWSoSYx0B7"
      },
      "source": [
        "# Evaluate baseline model\n",
        "yhat = model_baseline.predict(X_)\n",
        "yhat_val = model_baseline.predict(X_val_)\n",
        "acc = sklearn.metrics.accuracy_score(y_orig, yhat)\n",
        "acc_val = sklearn.metrics.accuracy_score(y_val_orig, yhat_val)\n",
        "print(f\"Training data accuracy  : {acc:.3f}\")\n",
        "print(f\"Validation data accuracy: {acc_val:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28AK6dsuvP-J"
      },
      "source": [
        "# Create deep CNN model\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    model = tensorflow.keras.models.Sequential()\n",
        "    # model.add(your own classification model code here!)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGGpoJ8TvWPC"
      },
      "source": [
        "# Train model\n",
        "history = model.fit(X, y,\n",
        "                    batch_size=64,\n",
        "                    epochs=2,  # Note, only two epochs here!\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAna0DNe8-C7"
      },
      "source": [
        "print(f\"Available history: {list(history.history.keys())}\")\n",
        "\n",
        "if len(history.history[\"loss\"]) > 1:\n",
        "  plt.figure()\n",
        "  plt.plot(history.history[\"loss\"])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss (categorical cross-entropy\")\n",
        "  plt.title(\"Learning curve for the CNN model\", fontsize=16)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFullmzNwBHS"
      },
      "source": [
        "# Evaluate the final model on the test data.\n",
        "# This is only ever done once, and as the last thing we do.\n",
        "# Training another model after this, based on the performance on the test data\n",
        "# leads to biased results!\n",
        "acc = model.evaluate(X, y, verbose=0)\n",
        "acc_val = model.evaluate(X_val, y_val, verbose=0)\n",
        "acc_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Training data error  : {acc[1]:.3f}\")\n",
        "print(f\"Validation data error: {acc_val[1]:.3f}\")\n",
        "print(f\"Test data error      : {acc_test[1]:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA0c7MYd0W4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}