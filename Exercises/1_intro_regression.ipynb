{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_intro_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InFu2x43UcJy"
      },
      "source": [
        "# Regression example\n",
        "California house-prices dataset. Predict median house value for California districts.\n",
        "\n",
        "More information about the dataset:\n",
        " * https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing\n",
        " * https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n",
        " * http://lib.stat.cmu.edu/datasets/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_c_4nIdUcmc"
      },
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import sklearn.preprocessing\n",
        "\n",
        "# Make the results reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load dataset\n",
        "data = sklearn.datasets.fetch_california_housing()\n",
        "\n",
        "# Split into training, validation, and test data sets\n",
        "n_train = int(data.data.shape[0] * 0.75 + 0.5)  # Train on 75 %\n",
        "n_val = int(data.data.shape[0] * 0.15 + 0.5)  # Validate on 15 %\n",
        "n_test = int(data.data.shape[0] * 0.10 + 0.5)  # Test on 10 %\n",
        "\n",
        "X = data.data[:n_train, :]\n",
        "y = data.target[:n_train]\n",
        "X_val = data.data[n_train:n_train + n_val, :]\n",
        "y_val = data.target[n_train:n_train + n_val]\n",
        "# Note! Do not use (at all!) the test data until the very end!\n",
        "X_test = data.data[n_train + n_val:, :]\n",
        "y_test = data.target[n_train + n_val:]\n",
        "\n",
        "print(f\"Training set size X  : {X.shape}\")\n",
        "print(f\"Training set size y  : {y.shape}\")\n",
        "print(f\"Validation set size X: {X_val.shape}\")\n",
        "print(f\"Validation set size y: {y_val.shape}\")\n",
        "print(f\"Test set size X      : {X_test.shape}\")\n",
        "print(f\"Test set size y      : {y_test.shape}\")\n",
        "print(f\"Feature names        : {data.feature_names}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLW1uqJ_bVPP"
      },
      "source": [
        "# Task1: Preprocess the data\n",
        "#  - Try without preprocessing, try with different kinds.\n",
        "#  - Evaluate and compare models on the validation data.\n",
        "#\n",
        "# Note that we fit the preprocessing function to the training data!\n",
        "# Then we apply the learned transformation to the validation and test data sets.\n",
        "standard_scaler = sklearn.preprocessing.StandardScaler()\n",
        "standard_scaler.fit(X)\n",
        "X_ = standard_scaler.transform(X)\n",
        "X_val_ = standard_scaler.transform(X_val)\n",
        "X_test_ = standard_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwP3qupaOdm"
      },
      "source": [
        "# Fit baseline model\n",
        "model_baseline = sklearn.linear_model.LinearRegression(fit_intercept=True)\n",
        "_ = model_baseline.fit(X_, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4BGPv9pbMk_"
      },
      "source": [
        "# Evaluate baseline model\n",
        "yhat = model_baseline.predict(X_)\n",
        "yhat_val = model_baseline.predict(X_val_)\n",
        "mse = sklearn.metrics.mean_squared_error(y, yhat)\n",
        "mse_val = sklearn.metrics.mean_squared_error(y_val, yhat_val)\n",
        "print(f\"Training data mean squared error  : {mse:.3f}\")\n",
        "print(f\"Validation data mean squared error: {mse_val:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLjuPfj1dmIN"
      },
      "source": [
        "# Task 2: Find a better model\n",
        "#  - Try different regression methods\n",
        "#  - Evaluate them on the validation data\n",
        "#  - Beat the baseline model and select the best one you can find\n",
        "#  - You can look here for potential models to use:\n",
        "#    https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "\n",
        "model = \"... add your own regression model code here!\"\n",
        "\n",
        "# Note that we fit on the preprocessed data in X_\n",
        "_ = model.fit(X_, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJchAM-EeJFF",
        "collapsed": true
      },
      "source": [
        "# Evaluate better model\n",
        "yhat = model.predict(X_)\n",
        "yhat_val = model.predict(X_val_)\n",
        "mse = sklearn.metrics.mean_squared_error(y, yhat)\n",
        "mse_val = sklearn.metrics.mean_squared_error(y_val, yhat_val)\n",
        "print(f\"Training data mean squared error  : {mse:.3f}\")\n",
        "print(f\"Validation data mean squared error: {mse_val:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiVg6buueWXE"
      },
      "source": [
        "# Task 3: Determine the importance of the input variables\n",
        "# ... your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7yxv79Mezh8"
      },
      "source": [
        "# Evaluate the final model on the test data.\n",
        "# This is only ever done once, and as the last thing we do.\n",
        "# Training another model after this, based on the performance on the test data\n",
        "# leads to biased results!\n",
        "yhat = model.predict(X_)\n",
        "yhat_val = model.predict(X_val_)\n",
        "yhat_test = model.predict(X_test_)\n",
        "mse = sklearn.metrics.mean_squared_error(y, yhat)\n",
        "mse_val = sklearn.metrics.mean_squared_error(y_val, yhat_val)\n",
        "mse_test = sklearn.metrics.mean_squared_error(y_test, yhat_test)\n",
        "print(f\"Training data mean squared error  : {mse:.3f}\")\n",
        "print(f\"Validation data mean squared error: {mse_val:.3f}\")\n",
        "print(f\"Test data mean squared error      : {mse_test:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKML5sYegvM9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}